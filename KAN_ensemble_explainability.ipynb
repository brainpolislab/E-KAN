{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de0cae7",
   "metadata": {},
   "source": [
    "# Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "#from sklearn_genetic import GASearchCV\n",
    "\n",
    "#from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "#from tpot import TPOTClassifier\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "#import tensorflow as tf\n",
    "#from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "#import keras \n",
    "#from keras.losses import BinaryCrossentropy\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import subprocess # TO RUN VBEOSA\n",
    "\n",
    "#from scikeras.wrappers import KerasClassifier # TO USE VOTING\n",
    "\n",
    "from EKAN_functions import *\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tabtransformertf.models.fttransformer import FTTransformerEncoder, FTTransformer\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09048cbf",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73677899",
   "metadata": {},
   "source": [
    "##### To estimate the model performance in a proper way a nested CV may be better than a normal CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4f805",
   "metadata": {},
   "source": [
    "### PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1521bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=pd.read_csv('your_dataset_corrected_total_x.csv')\n",
    "y=pd.read_csv('your_dataset_corrected_total_y.csv')\n",
    "models,model_p,dataset,dataset_p,Filt_1,Filt_2,sampled_arrays=KAN_tr_m(X,y.astype('int64'),X,y.astype('int64'),k=400,random_s=True,m='KAN',fil=True,subs=False,k1=4,k2=4,N=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faff808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KAN_pred(X_test):\n",
    "    \n",
    "    preds=[]\n",
    "\n",
    "\n",
    "    for model,filt,subgroup in zip(models,Filt_1,sampled_arrays):\n",
    "\n",
    "\n",
    "        X_test_s=X_test[filt]\n",
    "        X_test_s=pd.DataFrame(X_test_s)\n",
    "        dataset = {}\n",
    "        dataset['test_input'] = torch.from_numpy(X_test_s.values)\n",
    "        pred=torch.argmax(model(dataset['test_input']), dim=1).numpy().transpose()\n",
    "        preds.append(pred)\n",
    "    \n",
    "    preds=preds[Filt_2[0]]\n",
    "    preds=pd.DataFrame(preds)\n",
    "    dataset_p= {}\n",
    "    dataset_p['test_input'] = torch.from_numpy(preds.values)\n",
    "\n",
    "    y_pred=torch.argmax(model_p(dataset_p['test_input']), dim=1).numpy().transpose()\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ab2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.PermutationExplainer(KAN_pred,X)\n",
    "data_used=X\n",
    "\n",
    "shap_values = explainer.shap_values(data_used)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
